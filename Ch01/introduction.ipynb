{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question : {question}\n",
    "Answer : \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which NFL team won the Super Bowl in the 2010 season?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], template='Question : {question}\\nAnswer : ')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install hugginface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv_file = dotenv.find_dotenv()\n",
    "dotenv.load_dotenv(dotenv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev_folder\\anaconda3\\envs\\recent\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "\n",
    "# initialize Hub LLM\n",
    "hub_llm = HuggingFaceHub(\n",
    "    repo_id = 'google/flan-t5-xxl',\n",
    "    model_kwargs={'temperature':1e-10}\n",
    ")\n",
    "\n",
    "# create prompt template > LLM Chain\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=hub_llm\n",
    ")\n",
    "\n",
    "# ask the user question about NFL 2010\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking Multiple Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='')], [Generation(text='')], [Generation(text='')], [Generation(text='')]], llm_output=None, run=[RunInfo(run_id=UUID('32a28ea5-2e82-4763-8a0c-33ca0e22de07')), RunInfo(run_id=UUID('0b19d3db-bb07-4a65-a816-fab9c8869534')), RunInfo(run_id=UUID('30c84bfb-a7f2-4d26-8c7a-50c72ea2e44a')), RunInfo(run_id=UUID('4e161e8e-9c8a-47e0-bae4-9b274e60c04a'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 한번에 하나씩 실행하는 방법\n",
    "### generate를 사용해서 하나의 질문에 하나의 답변이 돌아오도록 구현\n",
    "qs = [\n",
    "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
    "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
    "    {'question': \"Who was the 12th person on the moon?\"},\n",
    "    {'question': \"How many eyes does a blade of grass have?\"}\n",
    "]\n",
    "res = llm_chain.generate(qs)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "multi_template = \"\"\"Answer the following questions one at a time.\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "long_prompt = PromptTemplate(\n",
    "    template=multi_template, input_variables=[\"questions\"])\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=hub_llm\n",
    ")\n",
    "\n",
    "qs_str = (\n",
    "    \"Which NFL team won the Super Bowl in the 2010 season?\\n\" +\n",
    "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\\n\" +\n",
    "    \"Who was the 12th person on the moon?\" +\n",
    "    \"How many eyes does a blade of grass have?\"\n",
    ")\n",
    "\n",
    "print(llm_chain.run(qs_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "davinci = OpenAI(model_name='text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=davinci\n",
    ")\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [\n",
    "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
    "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
    "    {'question': \"Who was the 12th person on the moon?\"},\n",
    "    {'question': \"How many eyes does a blade of grass have?\"}\n",
    "]\n",
    "llm_chain.generate(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=davinci\n",
    ")\n",
    "\n",
    "qs_str = (\n",
    "    \"Which NFL team won the Super Bowl in the 2010 season?\\n\" +\n",
    "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\\n\" +\n",
    "    \"Who was the 12th person on the moon?\" +\n",
    "    \"How many eyes does a blade of grass have?\"\n",
    ")\n",
    "\n",
    "print(llm_chain.run(qs_str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
